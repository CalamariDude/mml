{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "norm = lambda a : np.linalg.norm(a)\n",
    "dot = lambda a,b : np.dot(a,b)\n",
    "funky = lambda a,b : a[0]* b[0] - (a[0]*b[1] + a[1]*b[0]) + 2 * a[1]*b[1]\n",
    "print(norm([3,4]))\n",
    "print(dot([1,2],[3,4]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3\n"
     ]
    }
   ],
   "source": [
    "#⟨x, y⟩ := x1y1 − (x1y2 + x2y1) + 2x2y2\n",
    "print(1 * 3 - (1 * 4 + 2 * 3) + 2* 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "a set of basis vectors is a bilinear mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-51\n",
      "-51\n"
     ]
    }
   ],
   "source": [
    "lamb = 2\n",
    "phi = 3\n",
    "b1 ,b2, b3 = np.array([[1,2,3],[0,1,0] , [0,0,1]])\n",
    "b1, b2, b3 = np.array([[1,2],[2,3], [3,-2]])\n",
    "print(funky(lamb * b1 + phi * b2, b3))\n",
    "print(lamb * funky(b1,b3) + phi * funky(b2, b3))\n",
    "# print(np.dot(b1,b2))\n",
    "# print(np.dot(b1, 2 * np.asarray(b2)) == 2 * np.dot(b1, b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xhat [[2]\n",
      " [3]]\n",
      "yhat [[4]\n",
      " [5]]\n",
      "B shape (2, 2)\n",
      "A [[5 3]\n",
      " [3 2]]\n",
      "xhat [[2]\n",
      " [3]]\n",
      "shape of x and y (2, 1)\n",
      "[157]\n",
      "[[136]]\n"
     ]
    }
   ],
   "source": [
    "B = np.array([[1,1], [2,1]])\n",
    "psi = np.array([2,3])\n",
    "lamb = np.array([4,5])\n",
    "\n",
    "xhat = psi.reshape(-1,1)\n",
    "yhat = lamb.reshape(-1,1)\n",
    "print('xhat', xhat)\n",
    "print('yhat', yhat)\n",
    "# print(np.dot(psi, lamb))\n",
    "summation = 0 \n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        summation+=xhat[i] * np.dot(B[i], B[j]) * yhat[j]\n",
    "print('B shape', B.shape)\n",
    "A = B.T @ B\n",
    "print('A', A)\n",
    "print('xhat', xhat)\n",
    "print('shape of x and y', xhat.shape)\n",
    "print(summation)\n",
    "\n",
    "print(xhat.T @ A @ yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n",
      "[[1 0]\n",
      " [2 1]]\n",
      "[[99]]\n",
      "99\n",
      "[[5 2]\n",
      " [2 1]]\n",
      "[[99]]\n"
     ]
    }
   ],
   "source": [
    "B = np.array([[1,0], [2,1]])\n",
    "psi = np.array([2,3])\n",
    "lamb = np.array([4,5])\n",
    "\n",
    "x = B @ psi.reshape(-1,1)\n",
    "y = B @ lamb.reshape(-1,1)\n",
    "\n",
    "print(B.shape)\n",
    "print(B)\n",
    "print(x.T @ y)\n",
    "\n",
    "summation = 0 \n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        summation+=psi[i] * np.dot(B.T[i], B.T[j]) * lamb[j]\n",
    "print(summation)\n",
    "\n",
    "A = B.T @ B\n",
    "print(A)\n",
    "xhat = psi.reshape(-1,1)\n",
    "yhat = lamb.reshape(-1,1)\n",
    "print(xhat.T @ A @ yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Dot product: ${x_{1}y_{1} + x_{2}y_{2}}$\n",
    "\n",
    "Euclidean Metric: $\\sqrt{(x_{1}-y_{1})^{2} + (x_{2}-y_{2})^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# cauchy shwarz? show its relevance\n",
    "#example 3.5 what are the ramifications of using a different inner product. When is it even an inner product again?\n",
    "# norm definition\n",
    "a = [1, -1, 1]\n",
    "b = [-10, -1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function numpy.linalg.norm>"
      ]
     },
     "execution_count": 8,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare euclidean distance and dot product \n",
    "np.dot(a, a)\n",
    "\n",
    "np.linalg.norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Orthogonal Matrix\n",
    "    If a matrix is orthogonal it is also orthonormal\n",
    "    A and B here are both orthogonal matrix    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm of x 5.000000000000001\n",
      "[1 2] | | =  5.000000000000001\n",
      "[ 2.12132034 -0.70710678] | | =  2.2360679774997894\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1,0],[0,1]])\n",
    "B = np.array([[1/np.sqrt(2),1/np.sqrt(2)],[1/np.sqrt(2),-1/np.sqrt(2)]])\n",
    "x = np.array([1,2])\n",
    "print(\"Norm of x\", np.linalg.norm(x)**2)\n",
    "print(A @ x, '| | = ', np.linalg.norm(A@x) ** 2)\n",
    "print(B.T @ x, '| | = ', np.linalg.norm(B @ x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# A = []\n",
    "# V = np.array([[2,0],[0,1]])\n",
    "# u1 = V[:,0]/np.linalg.norm(V[:,0])\n",
    "# A.append(u1)\n",
    "# v2 = V[:,1]\n",
    "# u2 = (v2 - v2 @ u1)/np.linalg.norm(v2)\n",
    "# A.append(u2)\n",
    "\n",
    "# print(u1)\n",
    "# print(u2)\n",
    "# print(A)\n",
    "def gram_schmidt(V):\n",
    "    '''\n",
    "    Input: set of linearly independent vectors V (n,k)\n",
    "    Output: set of orthonormal basic vectors A (n,k)\n",
    "    '''\n",
    "    V = np.asarray(V)\n",
    "    A = []\n",
    "    u1 = V[:,0]/np.linalg.norm(V[:,0])\n",
    "    A.append(u1)\n",
    "    for i in range(1, len(V)):\n",
    "        vi = V[:,i].reshape(len(V[:,i]), 1)\n",
    "        proj = 0\n",
    "        for j in range(len(A)):\n",
    "            u = np.asarray(A).T[:,j]\n",
    "            u = u.reshape(len(u),1)\n",
    "            proj += vi *u *u\n",
    "        ui = (vi - proj)/np.linalg.norm(vi)\n",
    "        A.append(ui.reshape(len(ui)))\n",
    "    return np.asarray(A)\n",
    "\n",
    "V = [[3,0,0],[0,4,0],[0,0,5]]\n",
    "print(gram_schmidt(V))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.6 - 4.0\n",
    "\n",
    "### Old\n",
    "\n",
    "Subspace\n",
    "- Requirement i) v + w is closed\n",
    "- Requirement ii) c*v is closed\n",
    "- 0 exists\n",
    "- Examples like line, plane, single vector, whole space\n",
    "- Forgot: how many dimensions in a guy again? Same as vector space right? Don't confuse dimensions and number of basis. Has to be strictly less than.\n",
    "\n",
    "\n",
    "\n",
    "Affine space*\n",
    "- Off the origin\n",
    "\n",
    "What are the types of morphisms?\n",
    "- homomorphism mapping of algebraic structure, linear map. Same as functor in category theory\n",
    "- iso V -> W linear bijective, invertible. benefit just renaming graph replace with what you know\n",
    "- endo V > Vlinear, morphism to self. Endo that is isomorphism is automorphism\n",
    "- automorphism V -> V linear and bijective, isomorphism to self but better than endo because bijective\n",
    "\n",
    "### New\n",
    "\n",
    "Orthogonal Complement\n",
    "- You can describe a plane with a vector 'normal'. generalizes to hyperplane\n",
    "- x can be uniquely decomposed\n",
    "\n",
    "Inner product of functions\n",
    "- show this is true with sin(x) cos(x), function has limit \n",
    "\n",
    "Orthogonal projection\n",
    "- affine\n",
    "- idempotent\n",
    "\n",
    "Rotations\n",
    "- preserves distances, lengths, angles\n",
    "- not commutative 3D and onward\n",
    "\n",
    "Gram-Schmidt\n",
    "\n",
    "linear transformation vs projection \n",
    "\n",
    "represent linear transformation with matrix\n",
    "\n",
    "givens\n",
    "\n",
    "better viiusalizaion\n",
    "\n",
    "### Show/prove/experiments\n",
    "\n",
    "Rotation\n",
    "\n",
    "projections\n",
    "\n",
    "Representing a space with hyperplane\n",
    "\n",
    "What doeds it mean for functions to be orthogonal? Inner function of product \n",
    "\n",
    "f o g = f(g(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# space    [1 0 0], [0 1 0], [0 0 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "$x = \\sum \\lambda_{m}b_{m}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-98e4d0eed2dc>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-98e4d0eed2dc>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    subspace A [1 0], [0 1]\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "subspace A [1 0], [0 1]\n",
    "\n",
    "subspace A_c [0 0 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Determinant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regular -5.000000000000001\n",
      "scaled row addtion to another row -5.000000000000001\n",
      "order of row change 5.000000000000001\n",
      "Scaled one row of A only  -25.000000000000007\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1,2,3],[3,1,2],[0,0,1]])\n",
    "A_1= np.array([A[0],A[1] + 2* A[2], A[2]])\n",
    "A_order = np.array([A[2],A[1],A[0]])\n",
    "A_lamb = np.array([A[0],A[1],5 * A[2]])\n",
    "print('regular',np.linalg.det(A))\n",
    "print('scaled row addtion to another row',np.linalg.det(A_1))\n",
    "print('order of row change', np.linalg.det(A_order))\n",
    "print('Scaled one row of A only ', np.linalg.det(A_lamb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Hello"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Eigenvectors and Eigenvalues\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Really cool paper in Nature about how the brain uses eigenvectors for facial recognition: https://www.sciencedirect.com/science/article/pii/S009286741730538X\n",
    "- the experiment done is well-thought out. They use real eigenvectors, and map neural cells onto that plane. By then changing faces you can guess which neurons will fire based on how they have been mapped onto your eigenspace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Trace is useful because the trace is equal to the sum of the eigenvectors. Therefore you can guess some of the remaining eigenvalues when you have a few"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.91660753, 3.03553336, 1.87171306],\n",
       "       [4.84970385, 0.15544581, 1.49963581],\n",
       "       [3.36814714, 0.54331395, 4.60469438]])"
      ]
     },
     "execution_count": 54,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = 5 * np.random.rand(3,3)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# make it positive semidefinite\n",
    "A += 10 * np.eye(3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Case where we take the eigenvectors of $A$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values [17.07505163  6.58843285 12.01326322]\n",
      "vectors [[-0.46454453 -0.62057131 -0.43525846]\n",
      " [-0.48601431  0.75563848 -0.58120347]\n",
      " [-0.74026244  0.20952741  0.68757007]]\n",
      "largest eigenvector [-0.46454453 -0.62057131 -0.43525846]\n",
      "largest eigenvalue 17.075051633591308\n",
      "norm before transformation 0.8890220991911129\n",
      "norm after transformation 14.606744966308884\n",
      "scale factor =  16.430125842314833\n"
     ]
    }
   ],
   "source": [
    "values, vectors = np.linalg.eig(A)\n",
    "largestvalue = values[np.argmax(values)]\n",
    "largestvec = vectors[np.argmax(values)]\n",
    "newvec = A @ largestvec\n",
    "print('determinant', np.linalg.det(A))\n",
    "print('values', values)\n",
    "print('vectors', vectors)\n",
    "print('largest eigenvector', largestvec)\n",
    "print('largest eigenvalue', largestvalue)\n",
    "print('norm before transformation', np.linalg.norm(largestvec))\n",
    "print('norm after transformation', np.linalg.norm(newvec))\n",
    "print('scale factor = ', np.linalg.norm(newvec)/np.linalg.norm(vectors[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Case where we take the eigenvectors of $A^TA$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values [299.08522439  42.31084139 144.33234423]\n",
      "vectors [[-0.59547053 -0.66538751 -0.45019363]\n",
      " [-0.3786105   0.72667285 -0.573237  ]\n",
      " [-0.70856823  0.1708977   0.68463497]]\n",
      "largest eigenvector [-0.59547053 -0.66538751 -0.45019363]\n",
      "largest eigenvalue 299.08522438525114\n",
      "norm before transformation 0.9999999999999999\n",
      "norm after transformation 16.557000258195732\n",
      "scale factor =  16.557000258195735\n"
     ]
    }
   ],
   "source": [
    "values, vectors = np.linalg.eig(A.T @ A)\n",
    "largestvalue = values[np.argmax(values)]\n",
    "largestvec = vectors[np.argmax(values)]\n",
    "newvec = A @ largestvec\n",
    "print('values', values)\n",
    "print('vectors', vectors)\n",
    "print('largest eigenvector', largestvec)\n",
    "print('largest eigenvalue', largestvalue)\n",
    "print('norm before transformation', np.linalg.norm(largestvec))\n",
    "print('norm after transformation', np.linalg.norm(newvec))\n",
    "print('scale factor = ', np.linalg.norm(newvec)/np.linalg.norm(vectors[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Investigation Condition of a Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Defined as $\\frac{|A|}{|A^{-1}|}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values [0.39131003 0.50282386 0.76709185]\n",
      "vectors [[ 0.49318113 -0.41641998  0.40023597]\n",
      " [-0.78380105 -0.60369857  0.64377513]\n",
      " [ 0.37739672  0.67981058  0.65219993]]\n",
      "largest eigenvector [0.37739672 0.67981058 0.65219993]\n",
      "largest eigenvalue 0.7670918464894264\n",
      "norm before transformation 1.014857362380905\n",
      "norm after transformation 0.777369662179548\n",
      "scale factor =  1.0235443290888007\n",
      "condition number 4.0249400776458595\n",
      "sum of singular values 1.661225733447936\n",
      "largest singular value 4.024940077645863\n"
     ]
    }
   ],
   "source": [
    "values, vectors = np.linalg.eig(A)\n",
    "largestvalue = values[np.argmax(values)]\n",
    "largestvec = vectors[np.argmax(values)]\n",
    "newvec = A @ largestvec\n",
    "print('values', values)\n",
    "print('vectors', vectors)\n",
    "print('largest eigenvector', largestvec)\n",
    "print('largest eigenvalue', largestvalue)\n",
    "print('norm before transformation', np.linalg.norm(largestvec))\n",
    "print('norm after transformation', np.linalg.norm(newvec))\n",
    "print('scale factor = ', np.linalg.norm(newvec)/np.linalg.norm(vectors[0]))\n",
    "print('condition number', np.linalg.cond(A.T @ A))\n",
    "print('sum of singular values', np.sum(values))\n",
    "\n",
    "values, vectors = np.linalg.eig(A.T @ A)\n",
    "largestvalue = values[np.argmax(values)]\n",
    "largestvec = vectors[np.argmax(values)]\n",
    "print('largest singular value/smallest', values[np.argmax(values)]/values[np.argmin(values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 9, 0],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 52,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1,0,0],\n",
    "             [0,3,0],\n",
    "             [0,0,1]])\n",
    "A.T @ A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 3, 0],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 53,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Ubuntu Linux)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}